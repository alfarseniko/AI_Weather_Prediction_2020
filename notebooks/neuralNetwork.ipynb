{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../trainingData/GlobalLandTemperaturesByCity.csv')\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['dt'] = pd.to_datetime(df['dt'])\n",
    "\n",
    "# Extract features like day of the year, month, etc.\n",
    "df['day_of_year'] = df['dt'].dt.dayofyear\n",
    "df['month'] = df['dt'].dt.month\n",
    "df['year'] = df['dt'].dt.year\n",
    "df['day_of_week'] = df['dt'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame containing the dataset\n",
    "\n",
    "# Reduce the dataset to every 4th entry\n",
    "reduced_df = df.iloc[::4]\n",
    "\n",
    "# Now, work with reduced_df instead of df\n",
    "X = reduced_df.drop(['dt', 'AverageTemperature'], axis=1)  # Features\n",
    "y = reduced_df['AverageTemperature']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Here, we are using 80% of the data for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optionally, you can print the shapes of the resulting datasets to verify the split\n",
    "print(\"Training set - Features shape:\", X_train.shape)\n",
    "print(\"Training set - Target shape:\", y_train.shape)\n",
    "print(\"Testing set - Features shape:\", X_test.shape)\n",
    "print(\"Testing set - Target shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'City' and 'Country' columns\n",
    "X_train = X_train.drop(['City', 'Country'], axis=1)\n",
    "X_test = X_test.drop(['City', 'Country'], axis=1)\n",
    "print(\"Training set - Features shape:\", X_train.shape)\n",
    "print(\"Training set - Target shape:\", y_train.shape)\n",
    "print(\"Testing set - Features shape:\", X_test.shape)\n",
    "print(\"Testing set - Target shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert latitude and longitude values to numeric format\n",
    "def convert_to_numeric(value):\n",
    "    if isinstance(value, float):  # Check if value is already numeric\n",
    "        return value\n",
    "    direction = 1  # Assume positive direction by default\n",
    "    if value.endswith('S') or value.endswith('W'):\n",
    "        direction = -1  # Negative direction for South and West\n",
    "    return direction * float(value[:-1])  # Convert value to float and apply direction\n",
    "\n",
    "\n",
    "# Convert 'Latitude' and 'Longitude' columns to numeric format\n",
    "X_train['Latitude'] = X_train['Latitude'].apply(convert_to_numeric)\n",
    "X_train['Longitude'] = X_train['Longitude'].apply(convert_to_numeric)\n",
    "\n",
    "X_test['Latitude'] = X_test['Latitude'].apply(convert_to_numeric)\n",
    "X_test['Longitude'] = X_test['Longitude'].apply(convert_to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Latitude', 'Longitude', 'day_of_year', 'month', 'year', 'day_of_week']\n",
    "target = 'AverageTemperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Ensure the input shape matches the number of features in your dataset\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,), name='InputLayer'),  # Updated input shape to 7\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate MAE, MSE, and RMSE\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "mse = np.mean((predictions - y_test)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
